{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0ce2631-b840-4a7f-8183-fc50cb1977ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Spark aggregation functions\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "078a3193-f1a5-4e85-b50a-f80cf5908b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- listing_url: string (nullable = true)\n",
      " |-- scrape_id: long (nullable = true)\n",
      " |-- last_scraped: date (nullable = true)\n",
      " |-- source: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      " |-- neighborhood_overview: string (nullable = true)\n",
      " |-- picture_url: string (nullable = true)\n",
      " |-- host_id: integer (nullable = true)\n",
      " |-- host_url: string (nullable = true)\n",
      " |-- host_name: string (nullable = true)\n",
      " |-- host_since: date (nullable = true)\n",
      " |-- host_location: string (nullable = true)\n",
      " |-- host_about: string (nullable = true)\n",
      " |-- host_response_time: string (nullable = true)\n",
      " |-- host_response_rate: string (nullable = true)\n",
      " |-- host_acceptance_rate: string (nullable = true)\n",
      " |-- host_is_superhost: string (nullable = true)\n",
      " |-- host_thumbnail_url: string (nullable = true)\n",
      " |-- host_picture_url: string (nullable = true)\n",
      " |-- host_neighbourhood: string (nullable = true)\n",
      " |-- host_listings_count: integer (nullable = true)\n",
      " |-- host_total_listings_count: integer (nullable = true)\n",
      " |-- host_verifications: string (nullable = true)\n",
      " |-- host_has_profile_pic: string (nullable = true)\n",
      " |-- host_identity_verified: string (nullable = true)\n",
      " |-- neighbourhood: string (nullable = true)\n",
      " |-- neighbourhood_cleansed: string (nullable = true)\n",
      " |-- neighbourhood_group_cleansed: string (nullable = true)\n",
      " |-- latitude: double (nullable = true)\n",
      " |-- longitude: double (nullable = true)\n",
      " |-- property_type: string (nullable = true)\n",
      " |-- room_type: string (nullable = true)\n",
      " |-- accommodates: integer (nullable = true)\n",
      " |-- bathrooms: double (nullable = true)\n",
      " |-- bathrooms_text: string (nullable = true)\n",
      " |-- bedrooms: integer (nullable = true)\n",
      " |-- beds: integer (nullable = true)\n",
      " |-- amenities: string (nullable = true)\n",
      " |-- price: string (nullable = true)\n",
      " |-- minimum_nights: integer (nullable = true)\n",
      " |-- maximum_nights: integer (nullable = true)\n",
      " |-- minimum_minimum_nights: integer (nullable = true)\n",
      " |-- maximum_minimum_nights: integer (nullable = true)\n",
      " |-- minimum_maximum_nights: integer (nullable = true)\n",
      " |-- maximum_maximum_nights: integer (nullable = true)\n",
      " |-- minimum_nights_avg_ntm: double (nullable = true)\n",
      " |-- maximum_nights_avg_ntm: double (nullable = true)\n",
      " |-- calendar_updated: string (nullable = true)\n",
      " |-- has_availability: string (nullable = true)\n",
      " |-- availability_30: integer (nullable = true)\n",
      " |-- availability_60: integer (nullable = true)\n",
      " |-- availability_90: integer (nullable = true)\n",
      " |-- availability_365: integer (nullable = true)\n",
      " |-- calendar_last_scraped: date (nullable = true)\n",
      " |-- number_of_reviews: integer (nullable = true)\n",
      " |-- number_of_reviews_ltm: integer (nullable = true)\n",
      " |-- number_of_reviews_l30d: integer (nullable = true)\n",
      " |-- availability_eoy: integer (nullable = true)\n",
      " |-- number_of_reviews_ly: integer (nullable = true)\n",
      " |-- estimated_occupancy_l365d: integer (nullable = true)\n",
      " |-- estimated_revenue_l365d: integer (nullable = true)\n",
      " |-- first_review: date (nullable = true)\n",
      " |-- last_review: date (nullable = true)\n",
      " |-- review_scores_rating: double (nullable = true)\n",
      " |-- review_scores_accuracy: double (nullable = true)\n",
      " |-- review_scores_cleanliness: double (nullable = true)\n",
      " |-- review_scores_checkin: double (nullable = true)\n",
      " |-- review_scores_communication: double (nullable = true)\n",
      " |-- review_scores_location: double (nullable = true)\n",
      " |-- review_scores_value: double (nullable = true)\n",
      " |-- license: string (nullable = true)\n",
      " |-- instant_bookable: string (nullable = true)\n",
      " |-- calculated_host_listings_count: integer (nullable = true)\n",
      " |-- calculated_host_listings_count_entire_homes: integer (nullable = true)\n",
      " |-- calculated_host_listings_count_private_rooms: integer (nullable = true)\n",
      " |-- calculated_host_listings_count_shared_rooms: integer (nullable = true)\n",
      " |-- reviews_per_month: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "listings = spark.read.csv(\"data/listings.csv\", \n",
    "    header=True,\n",
    "    inferSchema=True,\n",
    "    sep=\",\", \n",
    "    quote='\"',\n",
    "    escape='\"', \n",
    "    multiLine=True,\n",
    "    mode=\"PERMISSIVE\" \n",
    ")\n",
    "listings.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32095599-a1da-408e-b315-3e0481e8bb22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:>                                                          (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- listing_id: long (nullable = true)\n",
      " |-- id: long (nullable = true)\n",
      " |-- date: date (nullable = true)\n",
      " |-- reviewer_id: integer (nullable = true)\n",
      " |-- reviewer_name: string (nullable = true)\n",
      " |-- comments: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "reviews = spark.read.csv(\"data/reviews.csv\", \n",
    "    header=True,\n",
    "    inferSchema=True,\n",
    "    sep=\",\",\n",
    "    quote='\"',\n",
    "    escape='\"',\n",
    "    multiLine=True,\n",
    "    mode=\"PERMISSIVE\"\n",
    ")\n",
    "reviews.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba5fc7ba-8be1-4680-aaf1-6724d1399e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+-------------+--------------+\n",
      "|id    |price  |price_numeric|price_category|\n",
      "+------+-------+-------------+--------------+\n",
      "|264776|$297.00|297.0        |Luxury        |\n",
      "|264777|$98.00 |98.0         |Mid-range     |\n",
      "|264778|$148.00|148.0        |Mid-range     |\n",
      "|264779|$144.00|144.0        |Mid-range     |\n",
      "|264780|$157.00|157.0        |Luxury        |\n",
      "|264781|$148.00|148.0        |Mid-range     |\n",
      "|264782|$120.00|120.0        |Mid-range     |\n",
      "|264783|$216.00|216.0        |Luxury        |\n",
      "|264789|$238.00|238.0        |Luxury        |\n",
      "|266037|$62.00 |62.0         |Mid-range     |\n",
      "+------+-------+-------------+--------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:>                                                          (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+\n",
      "|price_category|count|\n",
      "+--------------+-----+\n",
      "|Budget        |6612 |\n",
      "|Mid-range     |28108|\n",
      "|Luxury        |27964|\n",
      "+--------------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# 1. For each listing compute string category depending on its price, and add it as a new column.\n",
    "# A category is defined in the following way:\n",
    "#\n",
    "# * price < 50 -> \"Budget\"\n",
    "# * 50 <= price < 150 -> \"Mid-range\"\n",
    "# * price >= 150 -> \"Luxury\"\n",
    "# \n",
    "# Only include listings where the price is not null.\n",
    "# Count the number of listings in each category\n",
    "\n",
    "from pyspark.sql.functions import col, regexp_replace, udf\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "# Price -> numeric\n",
    "listings_num = listings.withColumn(\n",
    "    \"price_numeric\",\n",
    "    regexp_replace(col(\"price\"), \"[$,]\", \"\").cast(\"double\")\n",
    ")\n",
    "\n",
    "# UDF for price category\n",
    "def price_category(p):\n",
    "    if p is None:\n",
    "        return None\n",
    "    if p < 50:\n",
    "        return \"Budget\"\n",
    "    elif p < 150:\n",
    "        return \"Mid-range\"\n",
    "    else:\n",
    "        return \"Luxury\"\n",
    "\n",
    "price_category_udf = udf(price_category, StringType())\n",
    "\n",
    "# Filter out null prices and apply the UDF\n",
    "with_category = (\n",
    "    listings_num\n",
    "    .filter(col(\"price_numeric\").isNotNull())\n",
    "    .withColumn(\"price_category\", price_category_udf(col(\"price_numeric\")))\n",
    ")\n",
    "\n",
    "# Count number of listings per category (optional order)\n",
    "from pyspark.sql.functions import when as sf_when\n",
    "\n",
    "category_counts = (\n",
    "    with_category.groupBy(\"price_category\").count()\n",
    "    .withColumn(\n",
    "        \"order_key\",\n",
    "        sf_when(col(\"price_category\") == \"Budget\", 0)\n",
    "        .when(col(\"price_category\") == \"Mid-range\", 1)\n",
    "        .otherwise(2)\n",
    "    )\n",
    "    .orderBy(\"order_key\")\n",
    "    .drop(\"order_key\")\n",
    ")\n",
    "\n",
    "# Quick check\n",
    "with_category.select(\"id\", \"price\", \"price_numeric\", \"price_category\").show(10, truncate=False)\n",
    "category_counts.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69b6d82e-6255-40bb-be8f-837c0cef6571",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9:>                                                          (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------+-----------------+\n",
      "|name                                              |average_sentiment|\n",
      "+--------------------------------------------------+-----------------+\n",
      "|Beautiful house perfect for touring central London|9.0              |\n",
      "|Beautifully Contemporary Three Bedroom House      |9.0              |\n",
      "|Trent View a holiday home in London               |8.0              |\n",
      "|Gorgeous family home in Fulham for 6 by the river |8.0              |\n",
      "|Modern family home, large open kitchen & garden   |8.0              |\n",
      "|Central and Cozy 2 BR Flat next to Pimlico station|7.0              |\n",
      "|Gorgeous 4BR family home & garden                 |7.0              |\n",
      "|Comfortable Family Home                           |7.0              |\n",
      "|Peaceful cosy Ealing Apartment, private Garden    |7.0              |\n",
      "|large loft room with king size bed                |7.0              |\n",
      "+--------------------------------------------------+-----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# 2. In this task you will need to compute a santiment score per review, and then an average sentiment score per listing.\n",
    "# A santiment score indicates how \"positive\" or \"negative\" a review is. The higher the score the more positive it is, and vice-versa.\n",
    "#\n",
    "# To compute a sentiment score per review compute the number of positive words in a review and subtract the number of negative\n",
    "# words in the same review (the list of words is already provided)\n",
    "#\n",
    "# To complete this task, compute a DataFrame that contains the following fields:\n",
    "# * name - the name of a listing\n",
    "# * average_sentiment - average sentiment of reviews computed using the algorithm described above\n",
    "\n",
    "from pyspark.sql.functions import avg\n",
    "from pyspark.sql.types import FloatType\n",
    "import re\n",
    "\n",
    "# Lists of positive and negative words\n",
    "positive_words = {'good', 'great', 'excellent', 'amazing', 'fantastic', 'wonderful', 'pleasant', 'lovely', 'nice', 'enjoyed'}\n",
    "negative_words = {'bad', 'terrible', 'awful', 'horrible', 'disappointing', 'poor', 'hate', 'unpleasant', 'dirty', 'noisy'}\n",
    "\n",
    "# TODO: Implement the UDF\n",
    "def sentiment_score(comment):\n",
    "    if comment is None:\n",
    "        return None\n",
    "    # tokenize into alphabetic words, case-insensitive\n",
    "    tokens = re.findall(r\"[a-z]+\", comment.lower())\n",
    "    pos = sum(1 for t in tokens if t in positive_words)\n",
    "    neg = sum(1 for t in tokens if t in negative_words)\n",
    "    return float(pos - neg)\n",
    "\n",
    "sentiment_score_udf = udf(sentiment_score, FloatType())\n",
    "\n",
    "# Apply UDF per review\n",
    "reviews_with_sentiment = reviews.where(col(\"comments\").isNotNull()).withColumn(\n",
    "    \"sentiment_score\", sentiment_score_udf(col(\"comments\"))\n",
    ")\n",
    "\n",
    "# TODO: Create the final DataFrame\n",
    "# (join with listings to get 'name', compute average per listing)\n",
    "avg_sentiment_per_listing = (\n",
    "    reviews_with_sentiment.join(listings.select(col(\"id\").alias(\"listing_id\"), \"name\"), on=\"listing_id\", how=\"inner\")\n",
    "    .groupBy(\"name\")\n",
    "    .agg(avg(\"sentiment_score\").alias(\"average_sentiment\"))\n",
    ")\n",
    "\n",
    "# Example: show top 10 most positive listings based on average score\n",
    "avg_sentiment_per_listing.orderBy(col(\"average_sentiment\").desc()).show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "637b15b2-66df-4e9b-9bc1-8ba328e14aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 13:>                                                         (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------------------------------------------------+----------------------+-------------+\n",
      "|listing_id        |name                                             |average_comment_length|reviews_count|\n",
      "+------------------+-------------------------------------------------+----------------------+-------------+\n",
      "|618608352812465378|Beautiful Georgian top floor flat- 2 Bed.        |1300.1666666666667    |6            |\n",
      "|28508447          |The warm and cosy place.                         |1089.3333333333333    |6            |\n",
      "|627425975703032358|Superb loft beautiful quiet safe area near Center|951.7777777777778     |9            |\n",
      "|2197681           |Luxurious apartment in great area                |939.2                 |5            |\n",
      "|13891813          |Beautiful 2 Bedroom Apartment in South Kensington|905.0                 |5            |\n",
      "+------------------+-------------------------------------------------+----------------------+-------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# 3. Rewrite the following code from the previous exercise using SparkSQL:\n",
    "#\n",
    "# ```\n",
    "# from pyspark.sql.functions import length, avg, count\n",
    "# \n",
    "# reviews_with_comment_length = reviews.withColumn('comment_length', length('comments'))\n",
    "# reviews_with_comment_length \\\n",
    "#   .join(listings, reviews_with_comment_length.listing_id == listings.id, 'inner') \\\n",
    "#   .groupBy('listing_id').agg(\n",
    "#       avg(reviews_with_comment_length.comment_length).alias('average_comment_length'),\n",
    "#       count(reviews_with_comment_length.id).alias('reviews_count')\n",
    "#   ) \\\n",
    "#   .filter('reviews_count >= 5') \\\n",
    "#   .orderBy('average_comment_length', ascending=False) \\\n",
    "#   .show()\n",
    "# ```\n",
    "# This was a solution for the the task:\n",
    "#\n",
    "# \"Get top five listings with the highest average review comment length. Only return listings with at least 5 reviews\"\n",
    "\n",
    "reviews.createOrReplaceTempView(\"reviews\")\n",
    "listings.createOrReplaceTempView(\"listings\")\n",
    "\n",
    "sql_query = \"\"\"\n",
    "SELECT\n",
    "  l.id   AS listing_id,\n",
    "  l.name AS name,\n",
    "  AVG(LENGTH(r.comments)) AS average_comment_length,\n",
    "  COUNT(r.id)             AS reviews_count\n",
    "FROM reviews r\n",
    "JOIN listings l\n",
    "  ON r.listing_id = l.id\n",
    "WHERE r.comments IS NOT NULL\n",
    "GROUP BY l.id, l.name\n",
    "HAVING COUNT(r.id) >= 5\n",
    "ORDER BY average_comment_length DESC\n",
    "LIMIT 5\n",
    "\"\"\"\n",
    "\n",
    "spark.sql(sql_query).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd68c71-0ce8-4a21-be62-a822fce18522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. [Optional][Challenge]\n",
    "# Calculate an average time passed from the first review for each host in the listings dataset. \n",
    "# To implmenet a custom aggregation function you would need to use \"pandas_udf\" function to write a custom aggregation function.\n",
    "#\n",
    "# Documentation about \"pandas_udf\": https://spark.apache.org/docs/3.4.2/api/python/reference/pyspark.sql/api/pyspark.sql.functions.pandas_udf.html \n",
    "#\n",
    "# To use \"pandas_udf\" you would need to install two additional dependencies in the virtual environment you use for PySpark:\n",
    "# Run these commands:\n",
    "# ```\n",
    "# pip install pandas\n",
    "# pip install pyarrow\n",
    "# ```\n",
    "\n",
    "from pyspark.sql.functions import col, pandas_udf\n",
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.sql.functions import PandasUDFType\n",
    "import pandas as pd\n",
    "\n",
    "@pandas_udf(DoubleType(), functionType=PandasUDFType.GROUPED_AGG)\n",
    "def average_days_since_first_review_udf(first_review_series) -> float:\n",
    "    # TODO: Implement the UDF\n",
    "    pass\n",
    "\n",
    "listings \\\n",
    "  .filter(\n",
    "    listings.first_review.isNotNull()\n",
    "  ) \\\n",
    "  .groupBy('host_id') \\\n",
    "  .agg(\n",
    "    average_days_since_first_review_udf(listings.first_review).alias('average_days_since_first_review_days')\n",
    "  ) \\\n",
    "  .show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
